{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ## 1. Setup & Installation\n\n# %%\n!pip install transformers datasets sentence-transformers scikit-learn pandas numpy matplotlib seaborn plotly textblob nltk -q\n\n# %%\nimport torch\nimport torch.nn as nn\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.graph_objects as go\nimport plotly.express as px\nfrom plotly.subplots import make_subplots\nfrom transformers import (\n    AutoTokenizer, \n    AutoModelForSequenceClassification,\n    AutoModel,\n    pipeline\n)\nfrom sentence_transformers import SentenceTransformer, util\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import KMeans\nimport nltk\nfrom textblob import TextBlob\nimport re\nfrom datetime import datetime\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Download NLTK data\nnltk.download('punkt', quiet=True)\nnltk.download('vader_lexicon', quiet=True)\nfrom nltk.sentiment import SentimentIntensityAnalyzer\n\n# Set random seeds\ntorch.manual_seed(42)\nnp.random.seed(42)\n\n# Device configuration\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ## 2. Core Diary Analysis Engine\n\n# %%\nclass DiaryAnalyzer:\n    \"\"\"\n    Advanced diary analysis engine with 6-dimensional profiling\n    \"\"\"\n    def __init__(self):\n        # Initialize models\n        self.tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n        self.text_model = AutoModel.from_pretrained('distilbert-base-uncased')\n        \n        # Emotion detection model\n        self.emotion_classifier = pipeline(\n            \"text-classification\",\n            model=\"j-hartmann/emotion-english-distilroberta-base\",\n            top_k=None\n        )\n        \n        # Sentence transformer for semantic analysis\n        self.sentence_model = SentenceTransformer('all-MiniLM-L6-v2')\n        \n        # Sentiment analyzer\n        self.sia = SentimentIntensityAnalyzer()\n        \n        # Personality trait vocabulary\n        self.personality_indicators = {\n            'openness': ['creative', 'curious', 'imaginative', 'artistic', 'intellectual'],\n            'conscientiousness': ['organized', 'responsible', 'disciplined', 'thorough', 'reliable'],\n            'extraversion': ['outgoing', 'energetic', 'sociable', 'talkative', 'assertive'],\n            'agreeableness': ['kind', 'cooperative', 'empathetic', 'trusting', 'modest'],\n            'neuroticism': ['anxious', 'moody', 'tense', 'emotional', 'sensitive']\n        }\n        \n        # Life situation keywords\n        self.life_phase_keywords = {\n            'student': ['college', 'university', 'exam', 'study', 'assignment', 'professor'],\n            'professional': ['work', 'job', 'career', 'office', 'meeting', 'boss', 'colleague'],\n            'entrepreneur': ['business', 'startup', 'client', 'revenue', 'market', 'pitch'],\n            'transition': ['change', 'new', 'starting', 'leaving', 'moving', 'transition']\n        }\n        \n        # Value indicators\n        self.value_indicators = {\n            'family': ['family', 'parent', 'child', 'home', 'tradition'],\n            'growth': ['learn', 'improve', 'develop', 'grow', 'progress'],\n            'independence': ['freedom', 'autonomy', 'self-reliant', 'independent'],\n            'community': ['friends', 'community', 'together', 'support', 'help'],\n            'achievement': ['success', 'goal', 'achieve', 'accomplish', 'win']\n        }\n        \n    def analyze_diary_entry(self, text, timestamp=None):\n        \"\"\"\n        Complete 6-dimensional analysis of a diary entry\n        \"\"\"\n        results = {}\n        \n        # Basic text statistics\n        results['text_stats'] = self._get_text_stats(text)\n        \n        # 1. PRESENT LIFE SITUATION PARAMETERS\n        results['life_situation'] = self._analyze_life_situation(text)\n        \n        # 2. PERSONALITY PARAMETERS\n        results['personality'] = self._analyze_personality_traits(text)\n        \n        # 3. PRESENT EMOTIONAL STATUS PARAMETERS\n        results['emotional_status'] = self._analyze_emotional_status(text)\n        \n        # 4. LIFESTYLE & INTEREST COMPATIBILITY\n        results['lifestyle'] = self._analyze_lifestyle_interests(text)\n        \n        # 5. VALUES & WORLDVIEW ALIGNMENT\n        results['values'] = self._analyze_values_worldview(text)\n        \n        # 6. TIME-BASED DYNAMIC PARAMETERS\n        results['temporal_patterns'] = self._analyze_temporal_patterns(text, timestamp)\n        \n        # Overall scores\n        results['overall_profile'] = self._create_overall_profile(results)\n        \n        return results\n    \n    def _get_text_stats(self, text):\n        \"\"\"Basic text statistics\"\"\"\n        words = text.split()\n        sentences = nltk.sent_tokenize(text)\n        \n        return {\n            'word_count': len(words),\n            'sentence_count': len(sentences),\n            'avg_word_length': np.mean([len(w) for w in words]) if words else 0,\n            'avg_sentence_length': len(words)/len(sentences) if sentences else 0,\n            'unique_words': len(set(words)),\n            'lexical_diversity': len(set(words))/len(words) if words else 0\n        }\n    \n    def _analyze_life_situation(self, text):\n        \"\"\"\n        1. Life Situation Parameters\n        - Life Phase & Context\n        - Daily Rhythms & Availability\n        - Life Challenges & Pressures\n        \"\"\"\n        text_lower = text.lower()\n        \n        # Life Phase Detection\n        life_phase_scores = {}\n        for phase, keywords in self.life_phase_keywords.items():\n            score = sum([text_lower.count(keyword) for keyword in keywords])\n            life_phase_scores[phase] = score\n        \n        # Daily Rhythms (detect time mentions)\n        time_patterns = re.findall(r'\\b\\d{1,2}(?::\\d{2})?\\s*(?:am|pm|AM|PM)?\\b', text)\n        hour_mentions = re.findall(r'\\b(morning|afternoon|evening|night|midnight|dawn|dusk)\\b', text_lower)\n        \n        # Challenges & Pressures\n        pressure_words = ['stress', 'pressure', 'overwhelm', 'busy', 'rush', 'deadline', \n                         'hard', 'difficult', 'challenge', 'struggle', 'tired', 'exhaust']\n        challenge_score = sum([text_lower.count(word) for word in pressure_words])\n        \n        # Routine indicators\n        routine_words = ['routine', 'schedule', 'habit', 'daily', 'regular', 'always', 'usually', 'often']\n        routine_score = sum([text_lower.count(word) for word in routine_words])\n        \n        return {\n            'life_phase': max(life_phase_scores, key=life_phase_scores.get) if life_phase_scores else 'unknown',\n            'life_phase_scores': life_phase_scores,\n            'time_mentions': len(time_patterns),\n            'hour_references': hour_mentions,\n            'challenge_pressure': challenge_score / len(text.split()) * 100 if text else 0,\n            'routine_structure': routine_score / len(text.split()) * 100 if text else 0,\n            'busyness_index': (challenge_score + len(time_patterns)) / 10  # Normalized\n        }\n    \n    def _analyze_personality_traits(self, text):\n        \"\"\"\n        2. Personality Parameters\n        - Core Big Five Traits\n        - Extended Personality Dimensions\n        - Attachment Style Assessment\n        \"\"\"\n        text_lower = text.lower()\n        \n        # Big Five Trait Analysis\n        big_five_scores = {}\n        for trait, indicators in self.personality_indicators.items():\n            trait_score = sum([text_lower.count(indicator) for indicator in indicators])\n            big_five_scores[trait] = min(10, trait_score * 2)  # Scale to 0-10\n        \n        # Extended Dimensions\n        extended_traits = {\n            'introspection': self._count_words(text_lower, ['think', 'feel', 'reflect', 'consider', 'ponder']),\n            'optimism': self._analyze_optimism(text),\n            'resilience': self._analyze_resilience(text),\n            'empathy': self._count_words(text_lower, ['understand', 'feel', 'care', 'compassion', 'empathy']),\n            'perfectionism': self._count_words(text_lower, ['perfect', 'best', 'excellent', 'flawless', 'mistake'])\n        }\n        \n        # Attachment Style Clues\n        attachment_clues = {\n            'secure': self._count_words(text_lower, ['trust', 'comfortable', 'safe', 'supported', 'close']),\n            'anxious': self._count_words(text_lower, ['worry', 'anxious', 'fear', 'abandon', 'insecurity']),\n            'avoidant': self._count_words(text_lower, ['alone', 'independent', 'distance', 'space', 'detach'])\n        }\n        \n        return {\n            'big_five': big_five_scores,\n            'extended_traits': extended_traits,\n            'attachment_style': max(attachment_clues, key=attachment_clues.get),\n            'attachment_scores': attachment_clues,\n            'dominant_trait': max(big_five_scores, key=big_five_scores.get),\n            'personality_vector': list(big_five_scores.values())\n        }\n    \n    def _analyze_emotional_status(self, text):\n        \"\"\"\n        3. Emotional Status Parameters\n        - Current Emotional Landscape\n        - Emotional Needs & States\n        - Mental & Psychological State\n        \"\"\"\n        # Emotion classification\n        emotion_results = self.emotion_classifier(text[:512])[0]\n        emotions = {item['label']: item['score'] for item in emotion_results}\n        \n        # Sentiment analysis\n        sentiment = self.sia.polarity_scores(text)\n        text_blob = TextBlob(text)\n        \n        # Emotional complexity (variety of emotions mentioned)\n        emotion_words = ['happy', 'sad', 'angry', 'excited', 'frustrated', 'anxious', \n                        'calm', 'stressed', 'joy', 'fear', 'love', 'hate', 'content', 'worried']\n        emotion_variety = sum([1 for word in emotion_words if word in text.lower()])\n        \n        # Needs detection\n        needs = {\n            'connection': self._count_words(text.lower(), ['lonely', 'alone', 'connect', 'talk', 'share', 'friend']),\n            'achievement': self._count_words(text.lower(), ['accomplish', 'achieve', 'success', 'goal', 'progress']),\n            'security': self._count_words(text.lower(), ['safe', 'secure', 'stable', 'certain', 'predictable']),\n            'autonomy': self._count_words(text.lower(), ['freedom', 'control', 'choice', 'independent', 'decide'])\n        }\n        \n        # Mental state indicators\n        mental_state = {\n            'clarity': len(nltk.sent_tokenize(text)) / len(text.split()) * 100 if text else 0,\n            'rumination': text.lower().count('think') + text.lower().count('overthink'),\n            'present_focus': self._analyze_time_perspective(text),\n            'emotional_intensity': max(emotions.values()) if emotions else 0\n        }\n        \n        return {\n            'emotions': emotions,\n            'dominant_emotion': max(emotions, key=emotions.get) if emotions else 'neutral',\n            'sentiment': sentiment,\n            'subjectivity': text_blob.sentiment.subjectivity,\n            'emotional_complexity': emotion_variety,\n            'emotional_needs': needs,\n            'primary_need': max(needs, key=needs.get) if needs else 'none',\n            'mental_state': mental_state,\n            'wellness_score': (sentiment['compound'] + 1) * 50  # Convert to 0-100 scale\n        }\n    \n    def _analyze_lifestyle_interests(self, text):\n        \"\"\"\n        4. Lifestyle & Interest Compatibility\n        - Activity Preferences\n        - Interest Categories\n        \"\"\"\n        text_lower = text.lower()\n        \n        # Activity categories\n        activities = {\n            'creative': ['art', 'write', 'paint', 'draw', 'music', 'dance', 'photography'],\n            'academic': ['read', 'study', 'research', 'learn', 'book', 'course'],\n            'social': ['friend', 'party', 'social', 'gather', 'meet', 'hangout'],\n            'outdoor': ['walk', 'hike', 'park', 'nature', 'garden', 'exercise', 'sport'],\n            'indoor': ['home', 'movie', 'game', 'cook', 'bake', 'netflix', 'tv'],\n            'productive': ['work', 'project', 'organize', 'clean', 'plan', 'schedule']\n        }\n        \n        activity_scores = {}\n        for category, keywords in activities.items():\n            score = sum([text_lower.count(keyword) for keyword in keywords])\n            activity_scores[category] = score\n        \n        # Interest patterns\n        interests = {\n            'arts_culture': ['art', 'museum', 'theater', 'concert', 'film', 'exhibition'],\n            'technology': ['tech', 'computer', 'program', 'code', 'game', 'app', 'digital'],\n            'nature': ['nature', 'environment', 'animal', 'plant', 'outdoor', 'hike'],\n            'self_improvement': ['learn', 'grow', 'improve', 'develop', 'meditate', 'yoga'],\n            'social_justice': ['justice', 'equality', 'rights', 'community', 'help', 'support']\n        }\n        \n        interest_scores = {}\n        for category, keywords in interests.items():\n            score = sum([text_lower.count(keyword) for keyword in keywords])\n            interest_scores[category] = score\n        \n        return {\n            'activity_preferences': activity_scores,\n            'dominant_activity': max(activity_scores, key=activity_scores.get) if activity_scores else 'unknown',\n            'interest_categories': interest_scores,\n            'primary_interest': max(interest_scores, key=interest_scores.get) if interest_scores else 'unknown',\n            'lifestyle_vector': list(activity_scores.values())\n        }\n    \n    def _analyze_values_worldview(self, text):\n        \"\"\"\n        5. Values & Worldview Alignment\n        - Core Values\n        - Communication & Relationship Values\n        \"\"\"\n        text_lower = text.lower()\n        \n        # Core values detection\n        value_scores = {}\n        for value, keywords in self.value_indicators.items():\n            score = sum([text_lower.count(keyword) for keyword in keywords])\n            value_scores[value] = score\n        \n        # Relationship patterns\n        relationship_patterns = {\n            'collaboration': self._count_words(text_lower, ['together', 'team', 'collaborate', 'partner', 'cooperate']),\n            'independence': self._count_words(text_lower, ['alone', 'myself', 'independent', 'solo', 'individual']),\n            'support': self._count_words(text_lower, ['help', 'support', 'care', 'nurture', 'encourage']),\n            'competition': self._count_words(text_lower, ['win', 'compete', 'better', 'best', 'achieve'])\n        }\n        \n        # Communication style\n        communication = {\n            'directness': self._count_words(text_lower, ['said', 'told', 'asked', 'explain', 'clarify']),\n            'reflection': self._count_words(text_lower, ['think', 'feel', 'believe', 'consider', 'wonder']),\n            'emotional_expression': self._count_words(text_lower, ['feel', 'emotion', 'heart', 'soul', 'passion'])\n        }\n        \n        # Worldview indicators\n        worldview = {\n            'optimistic': self._count_words(text_lower, ['hope', 'future', 'better', 'improve', 'progress']),\n            'realistic': self._count_words(text_lower, ['fact', 'reality', 'actual', 'practical', 'logical']),\n            'spiritual': self._count_words(text_lower, ['spirit', 'soul', 'faith', 'belief', 'universe'])\n        }\n        \n        return {\n            'core_values': value_scores,\n            'primary_value': max(value_scores, key=value_scores.get) if value_scores else 'unknown',\n            'relationship_patterns': relationship_patterns,\n            'communication_style': max(communication, key=communication.get),\n            'worldview': worldview,\n            'values_vector': list(value_scores.values())\n        }\n    \n    def _analyze_temporal_patterns(self, text, timestamp=None):\n        \"\"\"\n        6. Time-Based Dynamic Parameters\n        - Temporal Patterns\n        - Change & Growth Indicators\n        \"\"\"\n        text_lower = text.lower()\n        \n        # Time references\n        time_references = {\n            'past': self._count_words(text_lower, ['yesterday', 'ago', 'was', 'were', 'had', 'remember']),\n            'present': self._count_words(text_lower, ['today', 'now', 'currently', 'present', 'is', 'am', 'are']),\n            'future': self._count_words(text_lower, ['tomorrow', 'will', 'going to', 'future', 'plan', 'hope'])\n        }\n        \n        # Change indicators\n        change_words = ['change', 'different', 'new', 'transition', 'evolve', 'grow', 'develop']\n        change_score = sum([text_lower.count(word) for word in change_words])\n        \n        # Growth mindset indicators\n        growth_mindset = self._count_words(text_lower, ['learn', 'improve', 'grow', 'develop', 'progress', 'better'])\n        \n        # Stability indicators\n        stability_words = ['same', 'routine', 'usual', 'consistent', 'stable', 'regular']\n        stability_score = sum([text_lower.count(word) for word in stability_words])\n        \n        # Temporal orientation (past, present, future focus)\n        total_time = sum(time_references.values())\n        if total_time > 0:\n            temporal_orientation = {\n                'past_focus': time_references['past'] / total_time * 100,\n                'present_focus': time_references['present'] / total_time * 100,\n                'future_focus': time_references['future'] / total_time * 100\n            }\n        else:\n            temporal_orientation = {'past_focus': 0, 'present_focus': 0, 'future_focus': 0}\n        \n        return {\n            'time_references': time_references,\n            'temporal_orientation': temporal_orientation,\n            'change_readiness': change_score / len(text.split()) * 100 if text else 0,\n            'growth_mindset': growth_mindset / len(text.split()) * 100 if text else 0,\n            'stability_index': stability_score / len(text.split()) * 100 if text else 0,\n            'temporal_balance': abs(time_references['present'] - time_references['future']) / 10\n        }\n    \n    def _create_overall_profile(self, analysis_results):\n        \"\"\"Create unified profile from all analyses\"\"\"\n        profile = {\n            'compatibility_score': self._calculate_compatibility_score(analysis_results),\n            'emotional_intelligence_score': analysis_results['emotional_status']['wellness_score'],\n            'stability_score': analysis_results['temporal_patterns']['stability_index'],\n            'growth_potential': analysis_results['temporal_patterns']['growth_mindset'],\n            'social_orientation': analysis_results['personality']['big_five']['extraversion'],\n            'need_for_connection': analysis_results['emotional_status']['emotional_needs']['connection'],\n            'stress_level': analysis_results['life_situation']['challenge_pressure']\n        }\n        \n        # Calculate overall wellness\n        profile['overall_wellness'] = (\n            profile['emotional_intelligence_score'] * 0.3 +\n            (100 - profile['stress_level']) * 0.3 +\n            profile['stability_score'] * 0.2 +\n            profile['growth_potential'] * 0.2\n        )\n        \n        return profile\n    \n    def _calculate_compatibility_score(self, results):\n        \"\"\"Calculate compatibility score for potential friendships\"\"\"\n        weights = {\n            'personality': 0.25,\n            'values': 0.20,\n            'lifestyle': 0.20,\n            'emotional_state': 0.15,\n            'life_situation': 0.10,\n            'temporal_patterns': 0.10\n        }\n        \n        # Normalize scores (simplified)\n        score = 0\n        score += np.mean(list(results['personality']['big_five'].values())) * weights['personality']\n        score += np.mean(list(results['values']['core_values'].values())) * weights['values']\n        score += np.mean(list(results['lifestyle']['activity_preferences'].values())) * weights['lifestyle']\n        score += results['emotional_status']['wellness_score'] / 100 * weights['emotional_state']\n        score += (100 - results['life_situation']['challenge_pressure']) / 100 * weights['life_situation']\n        score += results['temporal_patterns']['growth_mindset'] / 100 * weights['temporal_patterns']\n        \n        return min(100, score * 100)\n    \n    # Helper methods\n    def _count_words(self, text, words):\n        return sum([text.count(word) for word in words])\n    \n    def _analyze_optimism(self, text):\n        positive_words = ['good', 'great', 'happy', 'joy', 'excited', 'hope', 'positive']\n        negative_words = ['bad', 'terrible', 'sad', 'angry', 'worried', 'anxious', 'negative']\n        \n        pos_count = self._count_words(text.lower(), positive_words)\n        neg_count = self._count_words(text.lower(), negative_words)\n        \n        total = pos_count + neg_count\n        return pos_count / total * 100 if total > 0 else 50\n    \n    def _analyze_resilience(self, text):\n        resilient_words = ['overcome', 'persist', 'continue', 'strong', 'cope', 'adapt', 'bounce']\n        vulnerable_words = ['give up', 'quit', 'can\\'t', 'unable', 'helpless', 'overwhelm']\n        \n        res_count = self._count_words(text.lower(), resilient_words)\n        vul_count = self._count_words(text.lower(), vulnerable_words)\n        \n        total = res_count + vul_count\n        return res_count / total * 100 if total > 0 else 50\n    \n    def _analyze_time_perspective(self, text):\n        present_words = ['now', 'today', 'present', 'currently', 'moment']\n        non_present_words = ['tomorrow', 'yesterday', 'future', 'past', 'ago', 'later']\n        \n        pres_count = self._count_words(text.lower(), present_words)\n        non_pres_count = self._count_words(text.lower(), non_present_words)\n        \n        total = pres_count + non_pres_count\n        return pres_count / total * 100 if total > 0 else 50\n\n# %%\n# Initialize analyzer\nanalyzer = DiaryAnalyzer()\nprint(\"Diary Analyzer initialized successfully!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ## 3. Sample Diary Analysis\n\n# %%\n# Sample diary entries\nsample_diaries = [\n    {\n        \"text\": \"Today was incredibly productive! I finished my project proposal and even had time to go for a run in the park. Feeling accomplished but also looking forward to relaxing tonight with a good book. I've been thinking about starting a meditation practice to manage stress better. Met a new colleague at work who seems really interesting - we might grab coffee next week.\",\n        \"timestamp\": \"2024-01-15 19:30:00\",\n        \"mood\": \"accomplished\"\n    },\n    {\n        \"text\": \"Struggling with anxiety today. The workload feels overwhelming and I'm not sure if I'm on the right career path. I keep thinking about what my friends are achieving while I feel stuck. Wish I had someone to talk to who really understands. Maybe I should reach out to a therapist. On the bright side, I managed to cook a healthy dinner instead of ordering takeout.\",\n        \"timestamp\": \"2024-01-16 21:15:00\",\n        \"mood\": \"anxious\"\n    },\n    {\n        \"text\": \"Beautiful sunny day! Went hiking with friends and had deep conversations about life goals and values. Realized how much I value genuine connections over superficial interactions. Thinking about volunteering at the animal shelter on weekends. Feeling grateful for my support system and excited about personal growth journey. Need to balance social life with alone time for reflection.\",\n        \"timestamp\": \"2024-01-18 16:45:00\",\n        \"mood\": \"grateful\"\n    }\n]\n\n# %%\n# Analyze each diary\nprint(\"Analyzing sample diaries...\\n\")\nresults = []\nfor i, diary in enumerate(sample_diaries):\n    print(f\"\\n{'='*60}\")\n    print(f\"DIARY {i+1} ANALYSIS\")\n    print(f\"{'='*60}\")\n    \n    analysis = analyzer.analyze_diary_entry(diary['text'], diary['timestamp'])\n    results.append(analysis)\n    \n    # Print key insights\n    print(f\"Mood: {diary['mood']}\")\n    print(f\"Dominant Emotion: {analysis['emotional_status']['dominant_emotion']}\")\n    print(f\"Life Phase: {analysis['life_situation']['life_phase']}\")\n    print(f\"Personality: {analysis['personality']['dominant_trait']}\")\n    print(f\"Wellness Score: {analysis['overall_profile']['overall_wellness']:.1f}/100\")\n    print(f\"Compatibility Score: {analysis['overall_profile']['compatibility_score']:.1f}/100\")\n\n# %% [markdown]\n# ## 4. Comprehensive Visualization Dashboard\n\n# %%\ndef create_comprehensive_dashboard(results, diary_texts):\n    \"\"\"\n    Create interactive dashboard for all 6 dimensions\n    \"\"\"\n    fig = make_subplots(\n        rows=4, cols=3,\n        subplot_titles=(\n            'Emotional Landscape', 'Big Five Personality', 'Life Situation',\n            'Values Hierarchy', 'Lifestyle Preferences', 'Temporal Focus',\n            'Mental State Indicators', 'Activity Patterns', 'Relationship Needs',\n            'Overall Wellness Profile', 'Compatibility Matrix', 'Growth Indicators'\n        ),\n        specs=[\n            [{'type': 'heatmap'}, {'type': 'bar'}, {'type': 'radar'}],\n            [{'type': 'bar'}, {'type': 'polar'}, {'type': 'scatterpolar'}],\n            [{'type': 'scatter'}, {'type': 'bar'}, {'type': 'bar'}],\n            [{'type': 'radar'}, {'type': 'heatmap'}, {'type': 'gauge'}]\n        ],\n        vertical_spacing=0.08,\n        horizontal_spacing=0.08\n    )\n    \n    # Prepare data\n    emotions_list = ['joy', 'anger', 'sadness', 'fear', 'surprise', 'disgust', 'neutral']\n    personality_traits = ['openness', 'conscientiousness', 'extraversion', 'agreeableness', 'neuroticism']\n    \n    # 1. Emotional Landscape (Heatmap)\n    emotion_matrix = []\n    for result in results:\n        emotions = result['emotional_status']['emotions']\n        emotion_row = [emotions.get(e, 0) for e in emotions_list]\n        emotion_matrix.append(emotion_row)\n    \n    fig.add_trace(\n        go.Heatmap(\n            z=emotion_matrix,\n            x=emotions_list,\n            y=[f'Diary {i+1}' for i in range(len(results))],\n            colorscale='RdYlGn',\n            showscale=True,\n            colorbar=dict(title=\"Intensity\", len=0.2, y=0.9)\n        ),\n        row=1, col=1\n    )\n    \n    # 2. Big Five Personality (Bar)\n    personality_data = []\n    for i, result in enumerate(results):\n        traits = result['personality']['big_five']\n        personality_data.append(go.Bar(\n            name=f'Diary {i+1}',\n            x=personality_traits,\n            y=[traits[t] for t in personality_traits]\n        ))\n    \n    for bar in personality_data:\n        fig.add_trace(bar, row=1, col=2)\n    \n    # 3. Life Situation Radar\n    life_metrics = ['busyness_index', 'challenge_pressure', 'routine_structure']\n    for i, result in enumerate(results):\n        values = [result['life_situation'][metric] for metric in life_metrics]\n        fig.add_trace(\n            go.Scatterpolar(\n                r=values,\n                theta=life_metrics,\n                name=f'Diary {i+1}',\n                fill='toself'\n            ),\n            row=1, col=3\n        )\n    \n    # 4. Values Hierarchy (Bar)\n    values_list = ['family', 'growth', 'independence', 'community', 'achievement']\n    values_matrix = []\n    for result in results:\n        values = result['values']['core_values']\n        values_row = [values.get(v, 0) for v in values_list]\n        values_matrix.append(values_row)\n    \n    fig.add_trace(\n        go.Heatmap(\n            z=values_matrix,\n            x=values_list,\n            y=[f'Diary {i+1}' for i in range(len(results))],\n            colorscale='Blues',\n            showscale=True,\n            colorbar=dict(title=\"Strength\", len=0.2, y=0.6)\n        ),\n        row=2, col=1\n    )\n    \n    # 5. Lifestyle Preferences (Polar)\n    activities = ['creative', 'academic', 'social', 'outdoor', 'indoor', 'productive']\n    for i, result in enumerate(results):\n        pref = result['lifestyle']['activity_preferences']\n        values = [pref.get(a, 0) for a in activities]\n        fig.add_trace(\n            go.Scatterpolar(\n                r=values,\n                theta=activities,\n                name=f'Diary {i+1}',\n                fill='toself'\n            ),\n            row=2, col=2\n        )\n    \n    # 6. Temporal Focus\n    time_focus = ['past_focus', 'present_focus', 'future_focus']\n    for i, result in enumerate(results):\n        temporal = result['temporal_patterns']['temporal_orientation']\n        values = [temporal[t] for t in time_focus]\n        fig.add_trace(\n            go.Scatterpolar(\n                r=values,\n                theta=time_focus,\n                name=f'Diary {i+1}',\n                fill='toself'\n            ),\n            row=2, col=3\n        )\n    \n    # 7. Mental State Indicators\n    mental_metrics = ['clarity', 'rumination', 'present_focus', 'emotional_intensity']\n    mental_data = []\n    for i, result in enumerate(results):\n        mental = result['emotional_status']['mental_state']\n        mental_data.append(go.Scatter(\n            x=mental_metrics,\n            y=[mental[m] for m in mental_metrics],\n            name=f'Diary {i+1}',\n            mode='lines+markers'\n        ))\n    \n    for scatter in mental_data:\n        fig.add_trace(scatter, row=3, col=1)\n    \n    # 8. Activity Patterns\n    activity_categories = list(results[0]['lifestyle']['activity_preferences'].keys())\n    for i, result in enumerate(results):\n        activities = result['lifestyle']['activity_preferences']\n        fig.add_trace(\n            go.Bar(\n                x=activity_categories,\n                y=[activities[a] for a in activity_categories],\n                name=f'Diary {i+1}',\n                opacity=0.7\n            ),\n            row=3, col=2\n        )\n    \n    # 9. Relationship Needs\n    needs = ['connection', 'achievement', 'security', 'autonomy']\n    for i, result in enumerate(results):\n        emotional_needs = result['emotional_status']['emotional_needs']\n        fig.add_trace(\n            go.Bar(\n                x=needs,\n                y=[emotional_needs[n] for n in needs],\n                name=f'Diary {i+1}'\n            ),\n            row=3, col=3\n        )\n    \n    # 10. Overall Wellness Radar\n    wellness_metrics = ['emotional_intelligence_score', 'stability_score', \n                       'growth_potential', 'social_orientation', 'overall_wellness']\n    for i, result in enumerate(results):\n        profile = result['overall_profile']\n        values = [profile[m] for m in wellness_metrics]\n        fig.add_trace(\n            go.Scatterpolar(\n                r=values,\n                theta=wellness_metrics,\n                name=f'Diary {i+1}',\n                fill='toself'\n            ),\n            row=4, col=1\n        )\n    \n    # 11. Compatibility Matrix\n    compatibility_scores = [result['overall_profile']['compatibility_score'] for result in results]\n    \n    # Create compatibility matrix\n    n = len(results)\n    compat_matrix = np.zeros((n, n))\n    for i in range(n):\n        for j in range(n):\n            if i == j:\n                compat_matrix[i][j] = 100\n            else:\n                # Simplified compatibility calculation\n                score_i = results[i]['overall_profile']['compatibility_score']\n                score_j = results[j]['overall_profile']['compatibility_score']\n                compat_matrix[i][j] = (score_i + score_j) / 2\n    \n    fig.add_trace(\n        go.Heatmap(\n            z=compat_matrix,\n            x=[f'User {i+1}' for i in range(n)],\n            y=[f'User {i+1}' for i in range(n)],\n            colorscale='RdYlGn',\n            text=[[f\"{val:.0f}%\" for val in row] for row in compat_matrix],\n            texttemplate=\"%{text}\",\n            textfont={\"size\": 10},\n            showscale=True,\n            colorbar=dict(title=\"Match %\", len=0.2, y=0.1)\n        ),\n        row=4, col=2\n    )\n    \n    # 12. Growth Indicators (Gauge)\n    growth_indicators = {\n        'Change Readiness': np.mean([r['temporal_patterns']['change_readiness'] for r in results]),\n        'Growth Mindset': np.mean([r['temporal_patterns']['growth_mindset'] for r in results]),\n        'Learning Orientation': np.mean([r['lifestyle']['activity_preferences'].get('academic', 0) for r in results])\n    }\n    \n    fig.add_trace(\n        go.Indicator(\n            mode=\"gauge+number\",\n            value=growth_indicators['Growth Mindset'],\n            title={'text': \"Growth Potential\"},\n            domain={'x': [0, 1], 'y': [0, 1]},\n            gauge={\n                'axis': {'range': [0, 100]},\n                'bar': {'color': \"green\"},\n                'steps': [\n                    {'range': [0, 33], 'color': \"lightgray\"},\n                    {'range': [33, 66], 'color': \"gray\"},\n                    {'range': [66, 100], 'color': \"darkgray\"}\n                ]\n            }\n        ),\n        row=4, col=3\n    )\n    \n    # Update layout\n    fig.update_layout(\n        title_text=\"SoulSync AI: 6-Dimensional Diary Analysis Dashboard\",\n        height=1600,\n        showlegend=True,\n        template=\"plotly_dark\",\n        legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1)\n    )\n    \n    return fig\n\n# %%\n# Generate dashboard\ndashboard = create_comprehensive_dashboard(results, [d['text'] for d in sample_diaries])\ndashboard.show()\n\n# %% [markdown]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ## 5. Batch Processing & Insights Generation\n\n# %%\ndef analyze_diary_batch(diary_entries):\n    \"\"\"\n    Analyze multiple diary entries and generate insights\n    \"\"\"\n    all_results = []\n    insights = {\n        'emotional_patterns': [],\n        'personality_evolution': [],\n        'stress_trends': [],\n        'growth_metrics': [],\n        'compatibility_profiles': []\n    }\n    \n    for entry in diary_entries:\n        result = analyzer.analyze_diary_entry(entry['text'], entry.get('timestamp'))\n        all_results.append(result)\n    \n    # Generate insights\n    if len(all_results) > 1:\n        # Emotional patterns over time\n        emotions_over_time = []\n        for result in all_results:\n            emotions_over_time.append(result['emotional_status']['dominant_emotion'])\n        insights['emotional_patterns'] = emotions_over_time\n        \n        # Personality stability\n        personality_vectors = [result['personality']['personality_vector'] for result in all_results]\n        personality_stability = np.std(personality_vectors, axis=0).mean()\n        insights['personality_stability'] = personality_stability\n        \n        # Stress trends\n        stress_levels = [result['life_situation']['challenge_pressure'] for result in all_results]\n        insights['stress_trends'] = stress_levels\n        \n        # Growth metrics\n        growth_scores = [result['temporal_patterns']['growth_mindset'] for result in all_results]\n        insights['growth_trend'] = np.mean(growth_scores[-3:]) - np.mean(growth_scores[:3]) if len(growth_scores) >= 6 else 0\n        \n        # Compatibility profiles\n        compatibility_scores = [result['overall_profile']['compatibility_score'] for result in all_results]\n        insights['avg_compatibility'] = np.mean(compatibility_scores)\n        \n        # Generate recommendations\n        insights['recommendations'] = generate_recommendations(all_results[-1])\n    \n    return all_results, insights\n\ndef generate_recommendations(latest_analysis):\n    \"\"\"Generate personalized recommendations based on analysis\"\"\"\n    recommendations = []\n    \n    profile = latest_analysis['overall_profile']\n    emotional = latest_analysis['emotional_status']\n    personality = latest_analysis['personality']\n    life = latest_analysis['life_situation']\n    \n    # Emotional recommendations\n    if emotional['wellness_score'] < 60:\n        recommendations.append(\"Consider mindfulness practices to improve emotional well-being\")\n    \n    if emotional['emotional_needs']['connection'] > 5:\n        recommendations.append(\"High need for connection detected - consider joining interest-based communities\")\n    \n    # Personality-based recommendations\n    if personality['big_five']['neuroticism'] > 7:\n        recommendations.append(\"High neuroticism detected - stress management techniques recommended\")\n    \n    if personality['big_five']['extraversion'] < 4:\n        recommendations.append(\"Introverted tendencies - smaller group settings might be more comfortable\")\n    \n    # Life situation recommendations\n    if life['challenge_pressure'] > 70:\n        recommendations.append(\"High stress levels detected - consider work-life balance adjustments\")\n    \n    if life['routine_structure'] < 30:\n        recommendations.append(\"Low routine structure - establishing daily routines could improve stability\")\n    \n    # Growth recommendations\n    if latest_analysis['temporal_patterns']['growth_mindset'] > 70:\n        recommendations.append(\"Strong growth mindset - consider taking on new learning challenges\")\n    \n    return recommendations","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Batch analysis example\nprint(\"Performing batch analysis...\\n\")\nall_results, insights = analyze_diary_batch(sample_diaries)\n\nprint(\"INSIGHTS GENERATED:\")\nprint(\"-\" * 50)\nprint(f\"Emotional Patterns: {insights.get('emotional_patterns', [])}\")\nprint(f\"Personality Stability: {insights.get('personality_stability', 0):.2f}\")\nprint(f\"Average Stress Level: {np.mean(insights.get('stress_trends', [0])):.1f}%\")\nprint(f\"Growth Trend: {'Positive' if insights.get('growth_trend', 0) > 0 else 'Neutral'}\")\nprint(f\"Average Compatibility Score: {insights.get('avg_compatibility', 0):.1f}/100\")\nprint(\"\\nRECOMMENDATIONS:\")\nfor i, rec in enumerate(insights.get('recommendations', []), 1):\n    print(f\"{i}. {rec}\")\n\n# %% [markdown]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ## 6. Personality Compatibility Matching\n\n# %%\nclass PersonalityMatcher:\n    \"\"\"\n    Advanced personality matching based on 6-dimensional analysis\n    \"\"\"\n    def __init__(self):\n        self.user_profiles = {}\n        \n    def create_user_profile(self, user_id, analysis_results):\n        \"\"\"Create comprehensive user profile from analysis\"\"\"\n        profile = {\n            'id': user_id,\n            'personality_vector': analysis_results['personality']['personality_vector'],\n            'values_vector': analysis_results['values']['values_vector'],\n            'lifestyle_vector': analysis_results['lifestyle']['lifestyle_vector'],\n            'emotional_state': analysis_results['emotional_status']['wellness_score'],\n            'life_situation': analysis_results['life_situation']['busyness_index'],\n            'temporal_patterns': analysis_results['temporal_patterns']['growth_mindset'],\n            'dominant_trait': analysis_results['personality']['dominant_trait'],\n            'primary_value': analysis_results['values']['primary_value'],\n            'dominant_activity': analysis_results['lifestyle']['dominant_activity'],\n            'compatibility_score': analysis_results['overall_profile']['compatibility_score']\n        }\n        \n        self.user_profiles[user_id] = profile\n        return profile\n    \n    def calculate_compatibility(self, user1_id, user2_id):\n        \"\"\"Calculate multidimensional compatibility between two users\"\"\"\n        p1 = self.user_profiles[user1_id]\n        p2 = self.user_profiles[user2_id]\n        \n        # Calculate similarity scores for each dimension\n        dimension_scores = {}\n        \n        # 1. Personality compatibility (complementary vs similar)\n        personality_sim = self._cosine_similarity(p1['personality_vector'], p2['personality_vector'])\n        dimension_scores['personality'] = self._adjust_personality_compatibility(personality_sim, p1, p2)\n        \n        # 2. Values alignment\n        values_sim = self._cosine_similarity(p1['values_vector'], p2['values_vector'])\n        dimension_scores['values'] = values_sim * 100\n        \n        # 3. Lifestyle compatibility\n        lifestyle_sim = self._cosine_similarity(p1['lifestyle_vector'], p2['lifestyle_vector'])\n        dimension_scores['lifestyle'] = lifestyle_sim * 100\n        \n        # 4. Emotional resonance\n        emotional_diff = abs(p1['emotional_state'] - p2['emotional_state'])\n        dimension_scores['emotional'] = max(0, 100 - emotional_diff)\n        \n        # 5. Life situation compatibility\n        life_diff = abs(p1['life_situation'] - p2['life_situation'])\n        dimension_scores['life_situation'] = max(0, 100 - life_diff / 2)\n        \n        # 6. Growth trajectory alignment\n        growth_diff = abs(p1['temporal_patterns'] - p2['temporal_patterns'])\n        dimension_scores['growth'] = max(0, 100 - growth_diff)\n        \n        # Weighted overall compatibility\n        weights = {\n            'values': 0.25,\n            'personality': 0.20,\n            'lifestyle': 0.20,\n            'emotional': 0.15,\n            'life_situation': 0.10,\n            'growth': 0.10\n        }\n        \n        overall_score = sum(dimension_scores[dim] * weights[dim] for dim in dimension_scores)\n        \n        return {\n            'overall_score': overall_score,\n            'dimension_scores': dimension_scores,\n            'compatibility_level': self._get_compatibility_level(overall_score),\n            'strengths': self._identify_strengths(dimension_scores),\n            'considerations': self._identify_considerations(p1, p2, dimension_scores)\n        }\n    \n    def find_best_matches(self, user_id, top_n=5):\n        \"\"\"Find best matches for a user\"\"\"\n        matches = []\n        \n        for other_id in self.user_profiles:\n            if other_id != user_id:\n                compatibility = self.calculate_compatibility(user_id, other_id)\n                matches.append({\n                    'user_id': other_id,\n                    'score': compatibility['overall_score'],\n                    'details': compatibility\n                })\n        \n        # Sort by score\n        matches.sort(key=lambda x: x['score'], reverse=True)\n        return matches[:top_n]\n    \n    def _cosine_similarity(self, vec1, vec2):\n        \"\"\"Calculate cosine similarity between two vectors\"\"\"\n        vec1 = np.array(vec1)\n        vec2 = np.array(vec2)\n        return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n    \n    def _adjust_personality_compatibility(self, similarity, p1, p2):\n        \"\"\"Adjust personality compatibility (some traits work better with similarity, others with complementarity)\"\"\"\n        base_score = similarity * 100\n        \n        # Extraversion: Similarity is better\n        extraversion_diff = abs(p1['personality_vector'][2] - p2['personality_vector'][2])\n        if extraversion_diff < 2:  # Both similar in extraversion\n            base_score += 10\n        \n        # Neuroticism: Lower neuroticism combinations work better\n        neuroticism_avg = (p1['personality_vector'][4] + p2['personality_vector'][4]) / 2\n        if neuroticism_avg < 5:\n            base_score += 15\n        \n        return min(100, base_score)\n    \n    def _get_compatibility_level(self, score):\n        \"\"\"Get compatibility level description\"\"\"\n        if score >= 85:\n            return \"Exceptional Match\"\n        elif score >= 70:\n            return \"Strong Compatibility\"\n        elif score >= 55:\n            return \"Good Potential\"\n        elif score >= 40:\n            return \"Moderate Compatibility\"\n        else:\n            return \"Limited Compatibility\"\n    \n    def _identify_strengths(self, dimension_scores):\n        \"\"\"Identify strongest compatibility dimensions\"\"\"\n        strengths = []\n        for dim, score in dimension_scores.items():\n            if score >= 80:\n                strengths.append(f\"Strong {dim.replace('_', ' ').title()} alignment\")\n        return strengths if strengths else [\"Balanced across all dimensions\"]\n    \n    def _identify_considerations(self, p1, p2, dimension_scores):\n        \"\"\"Identify potential considerations or areas for awareness\"\"\"\n        considerations = []\n        \n        # Life phase considerations\n        if abs(p1['life_situation'] - p2['life_situation']) > 30:\n            considerations.append(\"Different life rhythms - coordination may need attention\")\n        \n        # Emotional state gap\n        if abs(p1['emotional_state'] - p2['emotional_state']) > 30:\n            considerations.append(\"Different emotional states - empathy and patience needed\")\n        \n        return considerations\n\n# %%","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Initialize matcher and create profiles\nmatcher = PersonalityMatcher()\n\nprint(\"Creating user profiles and calculating compatibility...\\n\")\nfor i, result in enumerate(all_results):\n    user_id = f\"user_{i+1:03d}\"\n    matcher.create_user_profile(user_id, result)\n    print(f\"Created profile for {user_id}\")\n\n# %%\n# Find matches for first user\nprint(f\"\\nFinding best matches for user_001:\")\nmatches = matcher.find_best_matches(\"user_001\", top_n=2)\n\nfor match in matches:\n    print(f\"\\nMatch with {match['user_id']}:\")\n    print(f\"  Overall Score: {match['score']:.1f}/100\")\n    print(f\"  Compatibility Level: {match['details']['compatibility_level']}\")\n    print(f\"  Strengths: {', '.join(match['details']['strengths'][:2])}\")\n    if match['details']['considerations']:\n        print(f\"  Considerations: {match['details']['considerations'][0]}\")\n\n# %% [markdown]\n# ## 7. Export & Report Generation\n\n# %%\ndef generate_analysis_report(user_id, analysis_results, matches=None):\n    \"\"\"Generate comprehensive analysis report\"\"\"\n    report = {\n        \"user_id\": user_id,\n        \"timestamp\": datetime.now().isoformat(),\n        \"summary\": generate_summary(analysis_results),\n        \"detailed_analysis\": extract_key_insights(analysis_results),\n        \"recommendations\": generate_recommendations(analysis_results),\n        \"compatibility_matches\": matches if matches else []\n    }\n    \n    return report\n\ndef generate_summary(analysis):\n    \"\"\"Generate executive summary\"\"\"\n    profile = analysis['overall_profile']\n    emotional = analysis['emotional_status']\n    personality = analysis['personality']\n    \n    summary = f\"\"\"\n    EMOTIONAL PROFILE: {emotional['dominant_emotion'].upper()} state\n    - Wellness Score: {profile['overall_wellness']:.1f}/100\n    - Emotional Intelligence: {profile['emotional_intelligence_score']:.1f}/100\n    \n    PERSONALITY PROFILE: {personality['dominant_trait'].upper()} dominant\n    - Most prominent trait: {max(personality['big_five'], key=personality['big_five'].get)}\n    - Attachment Style: {personality['attachment_style']}\n    \n    LIFE SITUATION: {analysis['life_situation']['life_phase'].upper()} phase\n    - Stress Level: {analysis['life_situation']['challenge_pressure']:.1f}%\n    - Routine Structure: {analysis['life_situation']['routine_structure']:.1f}%\n    \n    COMPATIBILITY POTENTIAL: {profile['compatibility_score']:.1f}/100\n    - Best suited for: {analysis['values']['primary_value']}-oriented individuals\n    - Optimal group size: {'Small (2-4)' if personality['big_five']['extraversion'] < 5 else 'Medium (4-6)'}\n    \"\"\"\n    \n    return summary\n\ndef extract_key_insights(analysis):\n    \"\"\"Extract key insights from analysis\"\"\"\n    insights = {}\n    \n    # Emotional insights\n    emotions = analysis['emotional_status']['emotions']\n    top_3_emotions = sorted(emotions.items(), key=lambda x: x[1], reverse=True)[:3]\n    insights['top_emotions'] = [f\"{e[0]} ({e[1]*100:.1f}%)\" for e in top_3_emotions]\n    \n    # Personality insights\n    big_five = analysis['personality']['big_five']\n    highest_trait = max(big_five, key=big_five.get)\n    lowest_trait = min(big_five, key=big_five.get)\n    insights['personality_extremes'] = {\n        'highest': f\"{highest_trait} ({big_five[highest_trait]:.1f}/10)\",\n        'lowest': f\"{lowest_trait} ({big_five[lowest_trait]:.1f}/10)\"\n    }\n    \n    # Values insights\n    values = analysis['values']['core_values']\n    top_value = max(values, key=values.get)\n    insights['core_value'] = f\"{top_value} (score: {values[top_value]})\"\n    \n    # Growth insights\n    temporal = analysis['temporal_patterns']\n    insights['temporal_focus'] = {\n        'orientation': max(temporal['temporal_orientation'], key=temporal['temporal_orientation'].get),\n        'growth_mindset': f\"{temporal['growth_mindset']:.1f}%\"\n    }\n    \n    return insights\n\n# %%\n# Generate report for first user\nprint(\"Generating comprehensive analysis report...\\n\")\nreport = generate_analysis_report(\"user_001\", all_results[0], matches)\n\nprint(\"ANALYSIS REPORT\")\nprint(\"=\" * 60)\nprint(report['summary'])\nprint(\"\\nKEY INSIGHTS:\")\nfor key, value in report['detailed_analysis'].items():\n    if isinstance(value, dict):\n        print(f\"  {key.replace('_', ' ').title()}:\")\n        for k, v in value.items():\n            print(f\"    - {k}: {v}\")\n    else:\n        print(f\"  {key.replace('_', ' ').title()}: {', '.join(value) if isinstance(value, list) else value}\")\n\nprint(\"\\nTOP MATCHES:\")\nfor match in report['compatibility_matches']:\n    print(f\"  - {match['user_id']}: {match['score']:.1f}/100 ({match['details']['compatibility_level']})\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ## 8. Integration with External Data (Example)\n\n# %%\ndef integrate_external_data(analysis_results, external_data=None):\n    \"\"\"Integrate with external data sources for enhanced analysis\"\"\"\n    enhanced_results = analysis_results.copy()\n    \n    if external_data:\n        # Example: Add weather data influence\n        if 'weather' in external_data:\n            weather_mood_map = {\n                'sunny': 0.2,  # Positive boost\n                'rainy': -0.1, # Slight negative\n                'cloudy': 0.0,  # Neutral\n                'stormy': -0.15 # Negative\n            }\n            \n            weather = external_data['weather']\n            boost = weather_mood_map.get(weather, 0.0)\n            enhanced_results['emotional_status']['wellness_score'] *= (1 + boost)\n        \n        # Example: Add time of day influence\n        if 'hour' in external_data:\n            hour = external_data['hour']\n            if 5 <= hour < 12:  # Morning\n                enhanced_results['emotional_status']['mental_state']['clarity'] *= 1.1\n            elif 21 <= hour < 24:  # Night\n                enhanced_results['emotional_status']['mental_state']['rumination'] *= 1.2\n    \n    return enhanced_results\n\n# %%\n# Example usage\nprint(\"\\nIntegrating external data...\")\nexternal_context = {'weather': 'sunny', 'hour': 14, 'season': 'winter'}\nenhanced_analysis = integrate_external_data(all_results[0], external_context)\n\nprint(f\"Original wellness score: {all_results[0]['emotional_status']['wellness_score']:.1f}\")\nprint(f\"Enhanced wellness score: {enhanced_analysis['emotional_status']['wellness_score']:.1f}\")\n\n# %% [markdown]\n# ## 9. Save & Export Functionality\n\n# %%\nimport json\nimport pickle\nfrom datetime import datetime\n\ndef save_analysis(analysis_results, filename=\"diary_analysis.json\"):\n    \"\"\"Save analysis results to JSON file\"\"\"\n    # Convert numpy arrays to lists for JSON serialization\n    def convert_for_json(obj):\n        if isinstance(obj, np.ndarray):\n            return obj.tolist()\n        elif isinstance(obj, np.integer):\n            return int(obj)\n        elif isinstance(obj, np.floating):\n            return float(obj)\n        return obj\n    \n    serializable_results = json.loads(json.dumps(analysis_results, default=convert_for_json))\n    \n    with open(filename, 'w') as f:\n        json.dump(serializable_results, f, indent=2)\n    \n    print(f\"Analysis saved to {filename}\")\n\ndef save_model_pipeline(filename=\"soulsync_pipeline.pkl\"):\n    \"\"\"Save the complete analysis pipeline\"\"\"\n    pipeline_data = {\n        'analyzer': analyzer,\n        'matcher': matcher,\n        'timestamp': datetime.now().isoformat(),\n        'version': '1.0'\n    }\n    \n    with open(filename, 'wb') as f:\n        pickle.dump(pipeline_data, f)\n    \n    print(f\"Pipeline saved to {filename}\")\n\n# %%\n# Save outputs\nprint(\"Saving outputs...\\n\")\nsave_analysis(all_results[0], \"user_001_analysis.json\")\nsave_model_pipeline()\n\n# Create summary CSV\nsummary_data = []\nfor i, result in enumerate(all_results):\n    summary_data.append({\n        'user_id': f'user_{i+1:03d}',\n        'dominant_emotion': result['emotional_status']['dominant_emotion'],\n        'wellness_score': result['overall_profile']['overall_wellness'],\n        'dominant_trait': result['personality']['dominant_trait'],\n        'life_phase': result['life_situation']['life_phase'],\n        'compatibility_score': result['overall_profile']['compatibility_score'],\n        'stress_level': result['life_situation']['challenge_pressure']\n    })\n\nsummary_df = pd.DataFrame(summary_data)\nsummary_df.to_csv('diary_analysis_summary.csv', index=False)\nprint(\"Summary CSV saved: diary_analysis_summary.csv\")\n\n# %% [markdown]\n# ## 10. Final Summary & Conclusion\n\n# %%\nprint(\"\\n\" + \"=\"*60)\nprint(\"ANALYSIS COMPLETE!\")\nprint(\"=\"*60)\nprint(f\"\\nTotal diaries analyzed: {len(all_results)}\")\nprint(f\"Models used: Emotion classifier, Sentence transformer, Personality analyzer\")\nprint(f\"Dimensions analyzed: 6 (Life, Personality, Emotional, Lifestyle, Values, Temporal)\")\nprint(f\"Outputs generated: JSON reports, CSV summary, Pickled pipeline\")\n\n# Create final summary table\nsummary_table = pd.DataFrame({\n    'Feature': [\n        'Emotion Detection',\n        'Personality Analysis', \n        'Life Situation Analysis',\n        'Lifestyle Preferences',\n        'Values & Worldview',\n        'Temporal Patterns',\n        'Compatibility Matching',\n        'Visualization Dashboard',\n        'Batch Processing'\n    ],\n    'Status': [\n        ' Complete',\n        ' Complete',\n        ' Complete',\n        ' Complete',\n        ' Complete',\n        ' Complete',\n        ' Complete',\n        ' Complete',\n        ' Complete'\n    ],\n    'Models Used': [\n        'DistilRoBERTa',\n        'Rule-based + Embeddings',\n        'Keyword Analysis',\n        'Category Mapping',\n        'Value Indicators',\n        'Time Reference Analysis',\n        'Cosine Similarity',\n        'Plotly Dashboard',\n        'Statistical Analysis'\n    ]\n})\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"PROJECT SUMMARY\")\nprint(\"=\"*60)\nprint(summary_table.to_string(index=False))\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"NEXT STEPS FOR DEPLOYMENT:\")\nprint(\"=\"*60)\nprint(\"1. Deploy as FastAPI service\")\nprint(\"2. Create Streamlit web interface\")\nprint(\"3. Add user authentication\")\nprint(\"4. Implement real-time diary analysis\")\nprint(\"5. Add friend matching notifications\")\nprint(\"6. Integrate with calendar/scheduling apps\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}